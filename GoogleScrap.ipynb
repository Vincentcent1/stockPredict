{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archived\n",
    "# MMDDYYYY\n",
    "# start = ['10','10','2016']\n",
    "# end = ['11','10','2016']\n",
    "# date = 'tbs=cdr%3A1%2Ccd_min%3A'+ start[0] + '%2F' + start[1] +'%2F' + start[2] + '%2Ccd_max%3A' + \\\n",
    "#         end[0] + '%2F' + end[1] + '%2F' + end[2]\n",
    "# ticker = '\"GOOGLE\"'\n",
    "# webfilter = \"Reuters.com\"\n",
    "# website ='https://www.google.com/search?&' + date + '&tbm=nws&q=site:{}+'.format(webfilter) + ticker\n",
    "# browser = webdriver.Chrome()\n",
    "# browser.get(website)\n",
    "# html = browser.page_source\n",
    "# # browser.quit()\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "# # a = soup.find('section', 'wrapper')\n",
    "# websites = []\n",
    "# for link in soup.findAll('a', attrs={'href': re.compile(\"(^https://)(?!.*google.com)(?!.*youtube.com)(?!.*blogger.com)\")}):\n",
    "#     link_str = link.get('href')\n",
    "#     if link_str not in websites:\n",
    "#         websites.append(link_str)\n",
    "# # for i in websites:\n",
    "# #     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Montly Fool\n",
    "# for site in websites:\n",
    "#     print(\"================================\")\n",
    "    \n",
    "#     sitetext = ''\n",
    "#     r = requests.get(site)\n",
    "#     websoup = BeautifulSoup(r.text)\n",
    "#     author_box = websoup.find('div',attrs={'class': re.compile(\"author-name\")})\n",
    "#     print(\"{}\".format(websoup.title.string))\n",
    "#     print()\n",
    "#     if (author_box):\n",
    "#         for e in author_box:\n",
    "#             if (e):\n",
    "#                 print(\"Author: {}\".format(e.strip()))\n",
    "#                 print()\n",
    "#             else:\n",
    "#                 print(\"Author: {}\".format(\"None\"))\n",
    "#                 print() \n",
    "#     else:\n",
    "#         print(\"Author: {}\".format(\"None\"))\n",
    "#         print()\n",
    "#     extractedweb = websoup.findAll('p')\n",
    "    \n",
    "#     for p in extractedweb:\n",
    "#         if(p.find(text=True)):\n",
    "#             if p.em:\n",
    "#                 continue\n",
    "#             elif (p.attrs=={'class':['primary_author-bio']}):\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 sitetext += p.text.strip() + \" \"\n",
    "#     print(sitetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MarketWatch\n",
    "# for site in websites:\n",
    "#     print(\"================================\")\n",
    "    \n",
    "#     sitetext = ''\n",
    "# #     browser.get(site)\n",
    "# #     html = browser.page_source\n",
    "# #     websoup = BeautifulSoup(html, 'html.parser')\n",
    "#     r = requests.get(site)\n",
    "#     websoup = BeautifulSoup(r.text)\n",
    "#     author_box = websoup.find('div',attrs={'class': re.compile(\"byline\")})\n",
    "#     print(\"{}\".format(websoup.title.string))\n",
    "#     print()\n",
    "#     if (author_box):\n",
    "#         for e in author_box:\n",
    "#             if (e.string.strip() == \"By\" or e.string.strip() == \"\"):\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 if (e):\n",
    "#                     print(\"Author: {}\".format(e.string.strip()))\n",
    "#                     print()\n",
    "#                 else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print() \n",
    "#     else:\n",
    "#         print(\"Author: {}\".format(\"None\"))\n",
    "#         print()\n",
    "#     extractedweb = websoup.findAll('p')\n",
    "    \n",
    "#     for p in extractedweb:\n",
    "#         if(p.find(text=True)):\n",
    "#             if (p.attrs=={'class':['bio']} or p.attrs=={'class':['copyright']} or p.attrs=={'class':['text', 'text--terms']} or p.attrs=={'class': ['correction']}):\n",
    "#                 continue\n",
    "#             elif (p.text.strip() == \"Join the conversation\"):\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 sitetext += p.text.strip() + \" \"\n",
    "#     print(sitetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Investopedia\n",
    "# for site in websites:\n",
    "#     print(\"================================\")\n",
    "    \n",
    "#     sitetext = ''\n",
    "# #     browser.get(site)\n",
    "# #     html = browser.page_source\n",
    "# #     websoup = BeautifulSoup(html, 'html.parser')\n",
    "#     r = requests.get(site)\n",
    "#     websoup = BeautifulSoup(r.text)\n",
    "#     author_box = websoup.find('span',attrs={'class': re.compile(\"by-author\")})\n",
    "#     print(\"{}\".format(websoup.title.string))\n",
    "#     print()\n",
    "#     if (author_box):\n",
    "#         counter = 0\n",
    "#         for e in author_box:\n",
    "#             if (counter == 1):\n",
    "#                 if (e):\n",
    "#                     print(\"Author: {}\".format(e.string.strip()))\n",
    "#                     print()\n",
    "#                 else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print() \n",
    "#             counter += 1\n",
    "#     else:\n",
    "#         print(\"Author: {}\".format(\"None\"))\n",
    "#         print()\n",
    "#     extractedweb = websoup.findAll('p')\n",
    "    \n",
    "#     for p in extractedweb:\n",
    "#         if(p.find(text=True)):\n",
    "#             if (p.attrs=={'class':['bio']} or p.attrs=={'class':['highlight']}):\n",
    "#                 continue\n",
    "#             elif (p.text.strip() == \"Want to learn how to invest?\"):\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 sitetext += p.text.strip()+ \" \"\n",
    "#     print(sitetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CNBC\n",
    "# for site in websites:\n",
    "#     print(\"================================\")\n",
    "    \n",
    "#     sitetext = ''\n",
    "# #     browser.get(site)\n",
    "# #     html = browser.page_source\n",
    "# #     websoup = BeautifulSoup(html, 'html.parser')\n",
    "#     r = requests.get(site)\n",
    "#     websoup = BeautifulSoup(r.text)\n",
    "#     author_box = websoup.find('div',attrs={'itemprop': re.compile(\"author\")})\n",
    "#     print(\"{}\".format(websoup.title.string))\n",
    "#     print()\n",
    "#     if (author_box):\n",
    "#         counter = 0\n",
    "#         for e in author_box:\n",
    "#             if (counter == 1):\n",
    "#                 if (e):\n",
    "#                     print(\"Author: {}\".format(e.string.strip()))\n",
    "#                     print()\n",
    "#                 else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print() \n",
    "#             counter += 1\n",
    "#     else:\n",
    "#         print(\"Author: {}\".format(\"None\"))\n",
    "#         print()\n",
    "#     extractedweb = websoup.findAll('p')\n",
    "    \n",
    "#     for p in extractedweb:\n",
    "#         if(p.find(text=True)):\n",
    "#             if (p.attrs=={'class':['label_share']} or p.attrs=={'class':['label']} or p.attrs=={'class':['Footer-sectionInfo']} or p.attrs=={'class':['Footer-copyright']}):\n",
    "#                 continue\n",
    "#             elif (p.input or p.em):\n",
    "#                 continue\n",
    "#             elif (p.text.strip() == \"Want to learn how to invest?\"):\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 sitetext += p.text.strip()+ \" \"\n",
    "#     print(sitetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reuters\n",
    "# for site in websites:\n",
    "#     print(\"================================\")\n",
    "#     sitetext = ''\n",
    "#     r = requests.get(site)\n",
    "#     websoup = BeautifulSoup(r.text)\n",
    "\n",
    "#     author_box = websoup.find(\"meta\",attrs = {'name':'Author'}, content=True)\n",
    "#     print(author_box['content'])\n",
    "#     print(\"{}\".format(websoup.title.string))\n",
    "#     print()\n",
    "\n",
    "#     if author_box:\n",
    "#         for e in author_box:\n",
    "#             print(e)\n",
    "#             if e:\n",
    "#                 print(\"Author: {}\".format(e.string.strip()))\n",
    "#                 print()\n",
    "#             else:\n",
    "#                 print(\"Author: {}\".format(\"None\"))\n",
    "#                 print() \n",
    "#     else:\n",
    "#         print(\"Author: {}\".format(\"None\"))\n",
    "#         print()\n",
    "        \n",
    "#     extractedweb = websoup.findAll('p')\n",
    "#     for p in extractedweb:\n",
    "#         if(p.find(text=True)):\n",
    "#             #print(p.attrs)\n",
    "#             if p.em:\n",
    "#                 continue\n",
    "#             if p.attrs == {'class': ['BylineBar_reading-time'], 'style': 'color:undefined'}:\n",
    "#                 continue\n",
    "#             if p.attrs == {'class': ['Attribution_content']}:\n",
    "#                 continue\n",
    "#             if p.attrs == {'div':['Attribution_container']}:\n",
    "#                 continue\n",
    "#             if p.span:\n",
    "#                 continue\n",
    "#             elif (p.attrs=={'a'}):\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 sitetext += p.text.strip() + \" \"\n",
    "#     print(sitetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing captcha\n",
    "# start = ['10','10','2016']\n",
    "# end = ['11','10','2016']\n",
    "# date = 'tbs=cdr%3A1%2Ccd_min%3A'+ start[0] + '%2F' + start[1] +'%2F' + start[2] + '%2Ccd_max%3A' + \\\n",
    "#         end[0] + '%2F' + end[1] + '%2F' + end[2]\n",
    "# website ='https://www.google.com/search?&' + date + '&tbm=nws&q=site:{}+'.format('reuters.com') + 'GOOGLE'\n",
    "# browser = webdriver.Firefox()\n",
    "# browser.get(website)\n",
    "# html = browser.page_source\n",
    "# # browser.quit()\n",
    "# soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "profile = webdriver.FirefoxProfile()\n",
    "profile.set_preference(\"general.useragent.override\", userAgents[random.randint(0,6)])\n",
    "driver = webdriver.Firefox(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "userAgents = [\"Mozilla/5.0 (X11; Linux i686; rv:64.0) Gecko/20100101 Firefox/64.0\",\n",
    "             \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:64.0) Gecko/20100101 Firefox/64.0\",\n",
    "             \"Mozilla/5.0 (X11; Linux i586; rv:63.0) Gecko/20100101 Firefox/63.0\",\n",
    "             \"Mozilla/5.0 (Windows NT 6.2; WOW64; rv:63.0) Gecko/20100101 Firefox/63.0\",\n",
    "             \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.10; rv:62.0) Gecko/20100101 Firefox/62.0\",\n",
    "             \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:10.0) Gecko/20100101 Firefox/62.0\",\n",
    "             \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.13; ko; rv:1.9.1b2) Gecko/20081201 Firefox/60.0\"]\n",
    "def scrapper(start_date, end_date, ticker):\n",
    "    '''\n",
    "    start_date: int value in form MMDDYYYY\n",
    "    end_date: int value in form MMDDYYYY\n",
    "    ticker: company ticker to search\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    scrapesites = ['reuters.com', 'investopedia.com', 'cnbc.com', 'fool.com', 'marketwatch.com']\n",
    "    \n",
    "    start = [str(int(int(start_date)/1000000)),str(int(int(start_date)/10000)%100),str(int(start_date)%10000)]\n",
    "    end = [str(int(int(end_date)/1000000)),str(int(int(end_date)/10000)%100),str(int(end_date)%10000)]\n",
    "    date = 'tbs=cdr%3A1%2Ccd_min%3A'+ start[0] + '%2F' + start[1] +'%2F' + start[2] + '%2Ccd_max%3A' + \\\n",
    "        end[0] + '%2F' + end[1] + '%2F' + end[2]\n",
    "    ticker = '\"' + ticker + '\"'\n",
    "    for ws in scrapesites:\n",
    "        authorval = \"\"\n",
    "        textval = \"\"\n",
    "        titleval = \"\"\n",
    "        website ='https://www.google.com/search?&' + date + '&tbm=nws&q=site:{}+'.format(ws) + ticker\n",
    "        profile = webdriver.FirefoxProfile()\n",
    "        profile.set_preference(\"general.useragent.override\", userAgents[random.randint(0,6)])\n",
    "        browser = webdriver.Firefox(profile)\n",
    "        browser.get(website)\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "#         while(soup.find('form',attrs={'id':'captcha-form'}) is not None):\n",
    "#             time.sleep(300)\n",
    "#             browser.get(website)\n",
    "#             html = browser.page_source\n",
    "#             soup = BeautifulSoup(html, 'html.parser')\n",
    "        browser.quit()\n",
    "        # a = soup.find('section', 'wrapper')\n",
    "        websites = []\n",
    "        for link in soup.findAll('a', attrs={'href': re.compile(\"(^https://)(?!.*google.com)(?!.*youtube.com)(?!.*blogger.com)\")}):\n",
    "            link_str = link.get('href')\n",
    "            if link_str not in websites:\n",
    "                websites.append(link_str)\n",
    "        if(ws == 'reuters.com'):\n",
    "            #Reuters\n",
    "            for site in websites:\n",
    "#                 print(\"================================\")\n",
    "                sitetext = ''\n",
    "                r = requests.get(site)\n",
    "                websoup = BeautifulSoup(r.text)\n",
    "\n",
    "                author_box = websoup.find(\"meta\",attrs = {'name':'Author'}, content=True)\n",
    "#                 print(author_box['content'])\n",
    "#                 print(\"{}\".format(websoup.title.string))\n",
    "#                 print()\n",
    "                titleval = websoup.title.string\n",
    "                if author_box:\n",
    "                    for e in author_box:\n",
    "                        print(e)\n",
    "                        if e:\n",
    "#                             print(\"Author: {}\".format(e.string.strip()))\n",
    "#                             print()\n",
    "                            authorval = e.string.strip()\n",
    "                            \n",
    "                        else:\n",
    "#                             print(\"Author: {}\".format(\"None\"))\n",
    "#                             print() \n",
    "                            authorval = \" \"\n",
    "                else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print()\n",
    "                    authorval = \" \"\n",
    "                print(authorval)\n",
    "                extractedweb = websoup.findAll('p')\n",
    "                for p in extractedweb:\n",
    "                    if(p.find(text=True)):\n",
    "                        #print(p.attrs)\n",
    "                        if p.em:\n",
    "                            continue\n",
    "                        if p.attrs == {'class': ['BylineBar_reading-time'], 'style': 'color:undefined'}:\n",
    "                            continue\n",
    "                        if p.attrs == {'class': ['Attribution_content']}:\n",
    "                            continue\n",
    "                        if p.attrs == {'div':['Attribution_container']}:\n",
    "                            continue\n",
    "                        if p.span:\n",
    "                            continue\n",
    "                        elif (p.attrs=={'a'}):\n",
    "                            continue\n",
    "                        else:\n",
    "                            sitetext += p.text.strip() + \" \"\n",
    "#                 print(sitetext)\n",
    "                textval = sitetext\n",
    "                df = df.append({\"Site\": \"Reuters\", \"Author\": authorval, \"Title\": titleval, \"Text\": textval, \"StartDate\": start_date, \"EndDate\": end_date}, ignore_index=True)\n",
    "#                 print(df.head(20))\n",
    "        elif (ws == 'investopedia.com'):\n",
    "            # Investopedia\n",
    "            for site in websites:\n",
    "#                 print(\"================================\")\n",
    "\n",
    "                sitetext = ''\n",
    "            #     browser.get(site)\n",
    "            #     html = browser.page_source\n",
    "            #     websoup = BeautifulSoup(html, 'html.parser')\n",
    "                r = requests.get(site)\n",
    "                websoup = BeautifulSoup(r.text)\n",
    "                author_box = websoup.find('span',attrs={'class': re.compile(\"by-author\")})\n",
    "#                 print(\"{}\".format(websoup.title.string))\n",
    "#                 print()\n",
    "                titleval = websoup.title.string\n",
    "                if (author_box):\n",
    "                    counter = 0\n",
    "                    for e in author_box:\n",
    "                        if (counter == 1):\n",
    "                            if (e):\n",
    "#                                 print(\"Author: {}\".format(e.string.strip()))\n",
    "#                                 print()\n",
    "                                authorval = e.string.strip()\n",
    "                            else:\n",
    "#                                 print(\"Author: {}\".format(\"None\"))\n",
    "#                                 print() \n",
    "                                authorval = \" \"\n",
    "                        counter += 1\n",
    "                else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print()\n",
    "                    authorval = \" \"\n",
    "                extractedweb = websoup.findAll('p')\n",
    "\n",
    "                for p in extractedweb:\n",
    "                    if(p.find(text=True)):\n",
    "                        if (p.attrs=={'class':['bio']} or p.attrs=={'class':['highlight']}):\n",
    "                            continue\n",
    "                        elif (p.text.strip() == \"Want to learn how to invest?\"):\n",
    "                            continue\n",
    "                        else:\n",
    "                            sitetext += p.text.strip()+ \" \"\n",
    "                textval = sitetext\n",
    "                df = df.append({\"Site\": \"Investopedia\", \"Author\": authorval, \"Title\": titleval, \"Text\": textval, \"StartDate\": start_date, \"EndDate\": end_date}, ignore_index=True)\n",
    "#                 print(df.head(20))\n",
    "        elif (ws == 'cnbc.com'):\n",
    "            # CNBC\n",
    "            for site in websites:\n",
    "#                 print(\"================================\")\n",
    "\n",
    "                sitetext = ''\n",
    "            #     browser.get(site)\n",
    "            #     html = browser.page_source\n",
    "            #     websoup = BeautifulSoup(html, 'html.parser')\n",
    "                r = requests.get(site)\n",
    "                websoup = BeautifulSoup(r.text)\n",
    "                author_box = websoup.find('div',attrs={'itemprop': re.compile(\"author\")})\n",
    "#                 print(\"{}\".format(websoup.title.string))\n",
    "#                 print()\n",
    "                titleval = websoup.title.string\n",
    "                if (author_box):\n",
    "                    counter = 0\n",
    "                    for e in author_box:\n",
    "                        if (counter == 1):\n",
    "                            if (e):\n",
    "#                                 print(\"Author: {}\".format(e.string.strip()))\n",
    "#                                 print()\n",
    "                                authorval = e.string.strip()\n",
    "                            else:\n",
    "#                                 print(\"Author: {}\".format(\"None\"))\n",
    "#                                 print() \n",
    "                                authorval = \" \"\n",
    "                        counter += 1\n",
    "                else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print()\n",
    "                    authorval = \" \"\n",
    "                extractedweb = websoup.findAll('p')\n",
    "\n",
    "                for p in extractedweb:\n",
    "                    if(p.find(text=True)):\n",
    "                        if (p.attrs=={'class':['label_share']} or p.attrs=={'class':['label']} or p.attrs=={'class':['Footer-sectionInfo']} or p.attrs=={'class':['Footer-copyright']}):\n",
    "                            continue\n",
    "                        elif (p.input or p.em):\n",
    "                            continue\n",
    "                        elif (p.text.strip() == \"Want to learn how to invest?\"):\n",
    "                            continue\n",
    "                        else:\n",
    "                            sitetext += p.text.strip()+ \" \"\n",
    "                textval = sitetext\n",
    "                df = df.append({\"Site\": \"CNBC\",\"Author\": authorval, \"Title\": titleval, \"Text\": textval, \"StartDate\": start_date, \"EndDate\": end_date}, ignore_index=True)\n",
    "#                 print(df.head(20))  \n",
    "        elif(ws == 'fool.com'):\n",
    "            # Montly Fool\n",
    "            for site in websites:\n",
    "#                 print(\"================================\")\n",
    "\n",
    "                sitetext = ''\n",
    "                r = requests.get(site)\n",
    "                websoup = BeautifulSoup(r.text)\n",
    "                author_box = websoup.find('div',attrs={'class': re.compile(\"author-name\")})\n",
    "#                 print(\"{}\".format(websoup.title.string))\n",
    "#                 print()\n",
    "                titleval = websoup.title.string\n",
    "                if (author_box):\n",
    "                    for e in author_box:\n",
    "                        if (e):\n",
    "#                             print(\"Author: {}\".format(e.strip()))\n",
    "#                             print()\n",
    "                            authorval = e.strip()\n",
    "                        else:\n",
    "#                             print(\"Author: {}\".format(\"None\"))\n",
    "#                             print() \n",
    "                            authorval = \" \"\n",
    "                else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print()\n",
    "                    authorval = \" \"\n",
    "                extractedweb = websoup.findAll('p')\n",
    "\n",
    "                for p in extractedweb:\n",
    "                    if(p.find(text=True)):\n",
    "                        if p.em:\n",
    "                            continue\n",
    "                        elif (p.attrs=={'class':['primary_author-bio']}):\n",
    "                            continue\n",
    "                        else:\n",
    "                            sitetext += p.text.strip() + \" \"\n",
    "                textval = sitetext\n",
    "                df = df.append({\"Site\": \"Fool\",\"Author\": authorval, \"Title\": titleval, \"Text\": textval, \"StartDate\": start_date, \"EndDate\": end_date}, ignore_index=True)\n",
    "#                 print(df.head(20))\n",
    "        elif (ws == 'marketwatch.com'):\n",
    "            # MarketWatch\n",
    "            for site in websites:\n",
    "#                 print(\"================================\")\n",
    "\n",
    "                sitetext = ''\n",
    "            #     browser.get(site)\n",
    "            #     html = browser.page_source\n",
    "            #     websoup = BeautifulSoup(html, 'html.parser')\n",
    "                r = requests.get(site)\n",
    "                websoup = BeautifulSoup(r.text)\n",
    "                author_box = websoup.find('div',attrs={'class': re.compile(\"byline\")})\n",
    "#                 print(\"{}\".format(websoup.title.string))\n",
    "#                 print()\n",
    "                titleval = websoup.title.string\n",
    "                if (author_box):\n",
    "                    for e in author_box:\n",
    "                        if e.string is None:\n",
    "                            continue\n",
    "                        if (e.string.strip() == \"By\" or e.string.strip() == \"\"):\n",
    "                            continue\n",
    "                        else:\n",
    "                            if (e):\n",
    "#                                 print(\"Author: {}\".format(e.string.strip()))\n",
    "#                                 print()\n",
    "                                authorval = e.string.strip()\n",
    "                            else:\n",
    "#                                 print(\"Author: {}\".format(\"None\"))\n",
    "#                                 print() \n",
    "                                authorval = \" \"\n",
    "                else:\n",
    "#                     print(\"Author: {}\".format(\"None\"))\n",
    "#                     print()\n",
    "                    authorval = \" \"\n",
    "                extractedweb = websoup.findAll('p')\n",
    "\n",
    "                for p in extractedweb:\n",
    "                    if(p.find(text=True)):\n",
    "                        if (p.attrs=={'class':['bio']} or p.attrs=={'class':['copyright']} or p.attrs=={'class':['text', 'text--terms']} or p.attrs=={'class': ['correction']}):\n",
    "                            continue\n",
    "                        elif (p.text.strip() == \"Join the conversation\"):\n",
    "                            continue\n",
    "                        else:\n",
    "                            sitetext += p.text.strip() + \" \"\n",
    "                textval = sitetext\n",
    "                df = df.append({\"Site\": \"MarketWatch\", \"Author\": authorval, \"Title\": titleval, \"Text\": textval, \"StartDate\": start_date, \"EndDate\": end_date}, ignore_index=True)\n",
    "#                 print(df.head(20))\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateStart = dt.datetime(2016,12,1)\n",
    "dateEnd = dt.datetime(2016,12,8)\n",
    "newStartDate = dateStart.strftime(\"%m%d%Y\")\n",
    "newEndDate = dateEnd.strftime(\"%m%d%Y\")\n",
    "counter = 0\n",
    "masterlist = []\n",
    "done = ['GOOGLE']\n",
    "companies_to_run = ['APPLE','AMAZON','ALIBABA','BANKOFAMERICA','Anheuser-BuschInBev','CITIGROUP',\n",
    "                   'CHINAMOBILE','CHEVRONCORPORATION','FACEBOOK','HOMEDEPOTINC', 'INTELCOPORATION', 'JOHNSON&JOHNSON',\n",
    "                   'JPMorganChase','MICROSOFT','Novartis', 'ORACLECORPORATION', 'Pfizer', 'Procter&Gamble',\n",
    "                   'RoyalDutchShellClassA', 'RoyalDutchShellClassB', 'AT&T', 'UnitedHealthGroup', 'VisaInc',\n",
    "                   'VerizonCommunications', 'Wells Fargo', 'Walmart', 'ExxonMobilCorporation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12082016\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# date_start = dt.strftime(startstart,\"%d%m%Y\")\n",
    "# print(datestart)\n",
    "# print(newStartDate)\n",
    "# print(newEndDate)\n",
    "\n",
    "\n",
    "for companies in companies_to_run:\n",
    "    dateStart = dt.datetime(2016,12,1)\n",
    "    dateEnd = dt.datetime(2016,12,8)\n",
    "    newStartDate = dateStart.strftime(\"%m%d%Y\")\n",
    "    newEndDate = dateEnd.strftime(\"%m%d%Y\")\n",
    "    while (int(newEndDate)%10000 != 2018):\n",
    "        print(newEndDate)\n",
    "        while True:\n",
    "            try:\n",
    "                extracted = scrapper(newStartDate, newEndDate, companies)\n",
    "            except:\n",
    "                continue\n",
    "            break\n",
    "        masterlist.append(extracted)\n",
    "        counter += 1\n",
    "        if (counter %10 == 0):\n",
    "            output = pd.concat(masterlist)\n",
    "            output.to_csv(\"{}{}.csv\".format(companies,counter//10), sep=\",\", index=False)\n",
    "            masterlist = []\n",
    "\n",
    "        dateStart += dt.timedelta(days = 7)\n",
    "        dateEnd += dt.timedelta(days = 7)\n",
    "        newStartDate = dateStart.strftime(\"%m%d%Y\")\n",
    "        newEndDate = dateEnd.strftime(\"%m%d%Y\")\n",
    "\n",
    "    output = pd.concat(masterlist)\n",
    "    output.to_csv(\"{}{}.csv\".format(companies,counter//10 + 1), sep=\",\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                               Author   EndDate          Site  \\\n",
       " 0                                                      04272017       Reuters   \n",
       " 1                                                      04272017       Reuters   \n",
       " 2                                                      04272017       Reuters   \n",
       " 3                                                      04272017       Reuters   \n",
       " 4                                                      04272017       Reuters   \n",
       " 5                                                      04272017       Reuters   \n",
       " 6                                                      04272017       Reuters   \n",
       " 7                                                      04272017       Reuters   \n",
       " 8                                                      04272017       Reuters   \n",
       " 9                                      Daniel Liberto  04272017  Investopedia   \n",
       " 10                                    Prableen Bajpai  04272017  Investopedia   \n",
       " 11                                  Mrinalini Krishna  04272017  Investopedia   \n",
       " 12                                     Daniel Liberto  04272017  Investopedia   \n",
       " 13                                      Rakesh Sharma  04272017  Investopedia   \n",
       " 14                                    Charles Bovaird  04272017  Investopedia   \n",
       " 15                                      Rakesh Sharma  04272017  Investopedia   \n",
       " 16                                        John Shinal  04272017          CNBC   \n",
       " 17                                  By Sheera Frenkel  04272017          CNBC   \n",
       " 18                                      Todd Haselton  04272017          CNBC   \n",
       " 19                                      Chantel McGee  04272017          CNBC   \n",
       " 20                                  Michelle Castillo  04272017          CNBC   \n",
       " 21                                 Anita Balakrishnan  04272017          CNBC   \n",
       " 22                                                     04272017          CNBC   \n",
       " 23                                                     04272017          CNBC   \n",
       " 24                                           Ari Levy  04272017          CNBC   \n",
       " 25                                           Ari Levy  04272017          CNBC   \n",
       " 26                                         Cora Lewis  04272017          CNBC   \n",
       " 27                                                     04272017          Fool   \n",
       " 28                                      Andrew Tonner  04272017          Fool   \n",
       " 29                                         Danny Vena  04272017          Fool   \n",
       " 30                                   Matthew Cochrane  04272017          Fool   \n",
       " 31                                       Chris Neiger  04272017          Fool   \n",
       " 32                                      Evan Niu, CFA  04272017          Fool   \n",
       " 33                                      Todd Campbell  04272017          Fool   \n",
       " 34  John Rosevear, Keith Speights, and Reuben Greg...  04272017          Fool   \n",
       " 35                                         Danny Vena  04272017          Fool   \n",
       " 36                                      Wendy Connick  04272017          Fool   \n",
       " 37                                      Sean Williams  04272017          Fool   \n",
       " 38                                    Jennifer Booton  04272017   MarketWatch   \n",
       " 39                                                     04272017   MarketWatch   \n",
       " 40                                        Tim Higgins  04272017   MarketWatch   \n",
       " 41                                                     04272017   MarketWatch   \n",
       " 42                                    Jeremy C. Owens  04272017   MarketWatch   \n",
       " 43                                      New York Post  04272017   MarketWatch   \n",
       " 44                                      Ciara Linnane  04272017   MarketWatch   \n",
       " 45                                        Jacob Passy  04272017   MarketWatch   \n",
       " 46                                       Tonya Garcia  04272017   MarketWatch   \n",
       " 47                                     Hannah Furfaro  04272017   MarketWatch   \n",
       " 48                                   Victor Reklaitis  04272017   MarketWatch   \n",
       " \n",
       "    StartDate                                               Text  \\\n",
       " 0   04202017  Alphabet’s profit beat Wall Street estimates a...   \n",
       " 1   04202017  Please choose from the options below: Go to th...   \n",
       " 2   04202017  The proliferation of hate speech and fake news...   \n",
       " 3   04202017  HANOI (Reuters) - Vietnam’s government said Fa...   \n",
       " 4   04202017  The company raised its full-year profit foreca...   \n",
       " 5   04202017  JAKARTA (Reuters) - Indonesia and the United S...   \n",
       " 6   04202017  NEW YORK (Reuters) - Forget about French elect...   \n",
       " 7   04202017  SINAGPORE (Reuters) - Companies from Singapore...   \n",
       " 8   04202017  WASHINGTON (Thomson Reuters Foundation) - Sex ...   \n",
       " 9   04202017  Find the best broker for your trading or inves...   \n",
       " 10  04202017  Find the best broker for your trading or inves...   \n",
       " 11  04202017  Find the best broker for your trading or inves...   \n",
       " 12  04202017  Find the best broker for your trading or inves...   \n",
       " 13  04202017  Find the best broker for your trading or inves...   \n",
       " 14  04202017  Find the best broker for your trading or inves...   \n",
       " 15  04202017  Find the best broker for your trading or inves...   \n",
       " 16  04202017  Google's own Internet services grabbed an incr...   \n",
       " 17  04202017  Google's servers in Cuba went live on Wednesda...   \n",
       " 18  04202017  Google has officially rolled out a new feature...   \n",
       " 19  04202017  Facebook and Google were the victims of an ela...   \n",
       " 20  04202017  Earlier this week, the advertising industry wa...   \n",
       " 21  04202017  The dominance of Facebook and Google when it c...   \n",
       " 22  04202017  Supported by By David Streitfeld The day is st...   \n",
       " 23  04202017  Fiat Chrysler and Google for the first time wi...   \n",
       " 24  04202017  Google has slowly been pulling back the curtai...   \n",
       " 25  04202017  Alphabet's effort to catch Amazon's cloud is t...   \n",
       " 26  04202017  Google has committed to not retaliate against ...   \n",
       " 27  04202017  Log in or create an account A MarketBeat accou...   \n",
       " 28  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 29  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 30  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 31  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 32  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 33  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 34  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 35  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 36  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 37  04202017  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 38  04202017  Published: Apr 27, 2017 1:46 p.m. ET Alphabet ...   \n",
       " 39  04202017  Supported by By David Streitfeld The day is st...   \n",
       " 40  04202017  Published: Apr 25, 2017 6:42 a.m. ET The effor...   \n",
       " 41  04202017  by \\nPaul Gillin UPDATED 00:31 EST . 25 APRIL ...   \n",
       " 42  04202017  Published: Apr 27, 2017 10:36 a.m. ET Three of...   \n",
       " 43  04202017  Published: Apr 20, 2017 1:53 p.m. ET By Tin-fo...   \n",
       " 44  04202017  Published: Apr 25, 2017 3:00 p.m. ET Station o...   \n",
       " 45  04202017  Published: Apr 23, 2017 2:55 p.m. ET The Digit...   \n",
       " 46  04202017  Published: Apr 22, 2017 9:59 a.m. ET Analysts ...   \n",
       " 47  04202017  Published: Apr 24, 2017 10:35 a.m. ET See whic...   \n",
       " 48  04202017  Published: Apr 27, 2017 12:16 p.m. ET It’s not...   \n",
       " \n",
       "                                                 Title  \n",
       " 0   \n",
       "                 Google parent Alphabet's prof...  \n",
       " 1   \n",
       "         \n",
       "         An Error has occured | Reu...  \n",
       " 2   \n",
       "                 EU mulls legislation in the f...  \n",
       " 3   \n",
       "                 Vietnam says Facebook commits...  \n",
       " 4   \n",
       "                 PayPal offers positive outloo...  \n",
       " 5   \n",
       "                 U.S. and Indonesia seek to cu...  \n",
       " 6   \n",
       "                 Wall Street gears up for busi...  \n",
       " 7   \n",
       "                 Tech firms race to spot video...  \n",
       " 8   \n",
       "                 Technology use by sex traffic...  \n",
       " 9   Google May Add an Ad-Blocking Feature to Chrom...  \n",
       " 10  Litecoin Price Rises on Hopes of SegWit Activa...  \n",
       " 11  Networks to Pour Billions into Original Conten...  \n",
       " 12  Marissa Mayer Will Make $186m from Verizon Dea...  \n",
       " 13  Analyst Downgrades Amazon Citing Need for Grea...  \n",
       " 14  Back From the Dead: Why Tobacco Stocks Are Soa...  \n",
       " 15  Services to Exceed 33% of Apple Gross Profit b...  \n",
       " 16  Alphabet's Google unit grabbing ever more ad r...  \n",
       " 17  Google just became the first foreign internet ...  \n",
       " 18      How to find where you parked with Google Maps  \n",
       " 19  Facebook and Google were victims of a $100 mil...  \n",
       " 20  Google ad blocker why advertisers might not ne...  \n",
       " 21  Alphabet, Google is a monopoly, says Jonathan ...  \n",
       " 22  Waymo to Offer Phoenix Area Access to Self-Dri...  \n",
       " 23  Google begins offering rides in self-driving cars  \n",
       " 24  Ex-Googlers left secretive AI unit to form Gro...  \n",
       " 25  Google Cloud takes on AWS in media biz:Tariq S...  \n",
       " 26  BuzzFeed: Google allows employees to protest M...  \n",
       " 27  \n",
       " \tMarketBeat: Stock Ratings, Research Tools a...  \n",
       " 28  \n",
       "       \n",
       "     Better Buy: Apple Inc. vs. Google ...  \n",
       " 29  \n",
       "       \n",
       "     Google and PayPal Join Forces on D...  \n",
       " 30  \n",
       "       \n",
       "     Google Wallet is Making Strides, B...  \n",
       " 31  \n",
       "       \n",
       "     Are Himax Technologies' Growth Day...  \n",
       " 32  \n",
       "       \n",
       "     Apple, Inc. Could Soon Compete Wit...  \n",
       " 33  \n",
       "       \n",
       "     Will You Get a Social Security Inc...  \n",
       " 34  \n",
       "       \n",
       "     3 Stocks to Hold for the Next 50 Y...  \n",
       " 35  \n",
       "       \n",
       "     Amazon's Alexa Just Took Another S...  \n",
       " 36  \n",
       "       \n",
       "     How to Get Social Security Benefit...  \n",
       " 37  \n",
       "       \n",
       "     Here's Why Barrick Gold Corp. Shar...  \n",
       " 38  Google earnings: A new approach arrives amid Y...  \n",
       " 39  Waymo to Offer Phoenix Area Access to Self-Dri...  \n",
       " 40  Alphabet’s Waymo offering families rides in se...  \n",
       " 41  On a big earnings day, tech giants are banking...  \n",
       " 42  The $2 trillion earnings day: Comcast and Abbv...  \n",
       " 43  Bose headphones spy on their owners, lawsuit a...  \n",
       " 44  iHeartRadio parent warns it may not survive an...  \n",
       " 45  When this savings app rolled out a monthly fee...  \n",
       " 46  Skechers fails to impress with first billion-d...  \n",
       " 47  New tech tool evaluates cities’ greenery - Mar...  \n",
       " 48  $10,000 for being bumped and 9 other big chang...  ,\n",
       "                   Author   EndDate          Site StartDate  \\\n",
       " 0                         05042017       Reuters  04272017   \n",
       " 1                         05042017       Reuters  04272017   \n",
       " 2                         05042017       Reuters  04272017   \n",
       " 3                         05042017       Reuters  04272017   \n",
       " 4                         05042017       Reuters  04272017   \n",
       " 5                         05042017       Reuters  04272017   \n",
       " 6                         05042017       Reuters  04272017   \n",
       " 7                         05042017       Reuters  04272017   \n",
       " 8                         05042017       Reuters  04272017   \n",
       " 9                         05042017       Reuters  04272017   \n",
       " 10        Daniel Liberto  05042017  Investopedia  04272017   \n",
       " 11       Charles Bovaird  05042017  Investopedia  04272017   \n",
       " 12         Rakesh Sharma  05042017  Investopedia  04272017   \n",
       " 13     Mrinalini Krishna  05042017  Investopedia  04272017   \n",
       " 14       Charles Bovaird  05042017  Investopedia  04272017   \n",
       " 15     Mrinalini Krishna  05042017  Investopedia  04272017   \n",
       " 16         Rakesh Sharma  05042017  Investopedia  04272017   \n",
       " 17        Daniel Liberto  05042017  Investopedia  04272017   \n",
       " 18        Daniel Liberto  05042017  Investopedia  04272017   \n",
       " 19  Shoshanna Delventhal  05042017  Investopedia  04272017   \n",
       " 20           John Shinal  05042017          CNBC  04272017   \n",
       " 21         Todd Haselton  05042017          CNBC  04272017   \n",
       " 22         Chantel McGee  05042017          CNBC  04272017   \n",
       " 23          Lucy Handley  05042017          CNBC  04272017   \n",
       " 24         Chantel McGee  05042017          CNBC  04272017   \n",
       " 25           Fred Imbert  05042017          CNBC  04272017   \n",
       " 26           Matt Hunter  05042017          CNBC  04272017   \n",
       " 27       Marguerite Ward  05042017          CNBC  04272017   \n",
       " 28       Marguerite Ward  05042017          CNBC  04272017   \n",
       " 29         Todd Haselton  05042017          CNBC  04272017   \n",
       " 30             Adam Levy  05042017          Fool  04272017   \n",
       " 31     Motley Fool Staff  05042017          Fool  04272017   \n",
       " 32       Steve Symington  05042017          Fool  04272017   \n",
       " 33         Sean Williams  05042017          Fool  04272017   \n",
       " 34         Todd Campbell  05042017          Fool  04272017   \n",
       " 35            Rich Smith  05042017          Fool  04272017   \n",
       " 36          Maxx Chatsko  05042017          Fool  04272017   \n",
       " 37         Sean Williams  05042017          Fool  04272017   \n",
       " 38               Leo Sun  05042017          Fool  04272017   \n",
       " 39          John Bromels  05042017          Fool  04272017   \n",
       " 40                        05042017   MarketWatch  04272017   \n",
       " 41       Therese Poletti  05042017   MarketWatch  04272017   \n",
       " 42     Giovanni Legorano  05042017   MarketWatch  04272017   \n",
       " 43       Robert McMillan  05042017   MarketWatch  04272017   \n",
       " 44        Shawn Langlois  05042017   MarketWatch  04272017   \n",
       " 45                        05042017   MarketWatch  04272017   \n",
       " 46       Jeremy C. Owens  05042017   MarketWatch  04272017   \n",
       " 47       Jurica Dujmovic  05042017   MarketWatch  04272017   \n",
       " 48       Jeremy C. Owens  05042017   MarketWatch  04272017   \n",
       " 49       Anora Mahmudova  05042017   MarketWatch  04272017   \n",
       " 50       George Friedman  05042017   MarketWatch  04272017   \n",
       " 51                        05042017   MarketWatch  04272017   \n",
       " 52          Tomi Kilgore  05042017   MarketWatch  04272017   \n",
       " \n",
       "                                                  Text  \\\n",
       " 0   SAN FRANCISCO (Reuters) - Microsoft Corp’s ann...   \n",
       " 1   Alphabet’s profit beat Wall Street estimates a...   \n",
       " 2   Google said on Wednesday that it had taken ste...   \n",
       " 3   MILAN (Reuters) - Alphabet Inc’s  Google has a...   \n",
       " 4   The ATO has increased scrutiny over how much t...   \n",
       " 5   LOS ANGELES (Reuters) - Family members of thre...   \n",
       " 6   Please choose from the options below: Go to th...   \n",
       " 7   SAN FRANCISCO (Reuters) - Facebook Inc’s growt...   \n",
       " 8   LONDON (Reuters) - Islamic State militants are...   \n",
       " 9   FRANKFURT, April 28 (Reuters) - Ergo, Munich R...   \n",
       " 10  Find the best broker for your trading or inves...   \n",
       " 11  Find the best broker for your trading or inves...   \n",
       " 12  Find the best broker for your trading or inves...   \n",
       " 13  Find the best broker for your trading or inves...   \n",
       " 14  Find the best broker for your trading or inves...   \n",
       " 15  Find the best broker for your trading or inves...   \n",
       " 16  Find the best broker for your trading or inves...   \n",
       " 17  Find the best broker for your trading or inves...   \n",
       " 18  Find the best broker for your trading or inves...   \n",
       " 19  Find the best broker for your trading or inves...   \n",
       " 20  Google CEO Sundar Pichai cashed in big during ...   \n",
       " 21  Don't worry if you accidentally opened that Go...   \n",
       " 22  Facebook and Google were the victims of an ela...   \n",
       " 23  Google and Facebook together took 20 percent o...   \n",
       " 24  If there was any doubt that Silicon Valley hat...   \n",
       " 25  Wall Street has high expectations for Amazon a...   \n",
       " 26  People like famed physicist Stephen Hawking an...   \n",
       " 27  Few will ever step foot inside the office of L...   \n",
       " 28  If you want to feel happier and less stressed,...   \n",
       " 29  Microsoft announced the Surface Laptop on Tues...   \n",
       " 30  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 31  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 32  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 33  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 34  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 35  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 36  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 37  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 38  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 39  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 40                                                      \n",
       " 41  Published: Apr 29, 2017 11:19 a.m. ET Opinion:...   \n",
       " 42  Published: May 4, 2017 2:30 p.m. ET By ROME --...   \n",
       " 43  Published: May 3, 2017 7:40 p.m. ET Innocent-l...   \n",
       " 44  Published: May 4, 2017 4:05 p.m. ET ‘It’s more...   \n",
       " 45  by \\nPaul Gillin UPDATED 00:31 EST . 25 APRIL ...   \n",
       " 46  Published: Apr 27, 2017 10:36 a.m. ET Three of...   \n",
       " 47  Published: May 2, 2017 2:21 p.m. ET Will Faceb...   \n",
       " 48  Published: Apr 29, 2017 11:18 a.m. ET Cloud-co...   \n",
       " 49  Published: Apr 28, 2017 4:57 p.m. ET All three...   \n",
       " 50  Published: May 2, 2017 11:38 a.m. ET When the ...   \n",
       " 51                                                      \n",
       " 52  Published: May 2, 2017 7:21 a.m. ET Twitter sh...   \n",
       " \n",
       "                                                 Title  \n",
       " 0   \n",
       "                 Google success in U.S. school...  \n",
       " 1   \n",
       "                 Google parent Alphabet's prof...  \n",
       " 2   \n",
       "                 Spam campaign targets Google ...  \n",
       " 3   \n",
       "                 Google to pay $334 million to...  \n",
       " 4   \n",
       "                 Google gets Australian tax of...  \n",
       " 5   \n",
       "                 Families of San Bernardino sh...  \n",
       " 6   \n",
       "         \n",
       "         An Error has occured | Reu...  \n",
       " 7   \n",
       "                 Facebook nears ad-only busine...  \n",
       " 8   \n",
       "                 Islamic State militants devel...  \n",
       " 9   \n",
       "                 Munich Re's troubled Ergo exp...  \n",
       " 10  Google CEO Pichai's Compensation Doubled in 20...  \n",
       " 11  How Trump Fueled Drone Maker Kratos' Stock Off...  \n",
       " 12  HBO to Remove Shows From Amazon Streaming by E...  \n",
       " 13   What Top Tech CEOs Made Last Year | Investopedia  \n",
       " 14  Back From the Dead: Why Tobacco Stocks Are Soa...  \n",
       " 15  Unfair Employee Treatment Cost Companies $16 B...  \n",
       " 16  Why Flying Cars Will Not Fly Soon (GOOG, EADSY...  \n",
       " 17  Verizon Bets on Autonomous Cars (VZ) | Investo...  \n",
       " 18  Twitter and Mark Cuban: Where's the AI? (TWTR)...  \n",
       " 19  Can Adidas Beat Nike as America’s Favorite Sho...  \n",
       " 20  Google CEO Sundar Pichai's compensation double...  \n",
       " 21  What to do if you opened the Google Doc phishi...  \n",
       " 22  Facebook and Google were victims of a $100 mil...  \n",
       " 23  Google and Facebook take 20 percent of total g...  \n",
       " 24  Google's Eric Schmidt: H-1B limit is stupidest...  \n",
       " 25  Wall Street now predicts both Amazon and Alpha...  \n",
       " 26  Google's Peter Norvig: how to prepare for AI j...  \n",
       " 27  Ex-Google exec on the leadership strategy she ...  \n",
       " 28  Former Google career coach: This is the formul...  \n",
       " 29  Microsoft Surface Laptop: sneak attack against...  \n",
       " 30  \n",
       "       \n",
       "     Nobody Can Stop Facebook and Googl...  \n",
       " 31  \n",
       "       \n",
       "     Check Out The Motley Fool's Skill ...  \n",
       " 32  \n",
       "       \n",
       "     Yandex N.V. Is Rightly Excited for...  \n",
       " 33  \n",
       "       \n",
       "     Here's Why Endeavour Silver Corp. ...  \n",
       " 34  \n",
       "       \n",
       "     What's Worrying Me About Biogen --...  \n",
       " 35  \n",
       "       \n",
       "     Why Synchrony Financial Stock Plum...  \n",
       " 36  \n",
       "       \n",
       "     Here's Why Sunoco LP Rose 25.8% in...  \n",
       " 37  \n",
       "       \n",
       "     This Major Catalyst Sent Geron Cor...  \n",
       " 38  \n",
       "       \n",
       "     Where Will Twilio Inc. Be in 10 Ye...  \n",
       " 39  \n",
       "       \n",
       "     3 Things You Didn't Know About Con...  \n",
       " 40                                      404 Not Found  \n",
       " 41  Google survives YouTube ad controversy, for no...  \n",
       " 42  Google reaches tax settlement in Italy - Marke...  \n",
       " 43  Quick-spreading phishing attack targets Google...  \n",
       " 44  Alphabet’s Eric Schmidt says he’s a ‘denier’ w...  \n",
       " 45  On a big earnings day, tech giants are banking...  \n",
       " 46  The $2 trillion earnings day: Comcast and Abbv...  \n",
       " 47  This is the gadget that could one day replace ...  \n",
       " 48  Amazon is worth so much because its cloud  bus...  \n",
       " 49  Stock market ends session lower, but Dow books...  \n",
       " 50  Next recession will hit during Trump’s first t...  \n",
       " 51                                      403 Forbidden  \n",
       " 52  Twitter’s stock officially enters new bull mar...  ,\n",
       "                   Author   EndDate          Site StartDate  \\\n",
       " 0                         05112017       Reuters  05042017   \n",
       " 1                         05112017       Reuters  05042017   \n",
       " 2                         05112017       Reuters  05042017   \n",
       " 3                         05112017       Reuters  05042017   \n",
       " 4                         05112017       Reuters  05042017   \n",
       " 5                         05112017       Reuters  05042017   \n",
       " 6                         05112017       Reuters  05042017   \n",
       " 7                         05112017       Reuters  05042017   \n",
       " 8                         05112017       Reuters  05042017   \n",
       " 9                         05112017       Reuters  05042017   \n",
       " 10                        05112017       Reuters  05042017   \n",
       " 11        Donna Fuscaldo  05112017  Investopedia  05042017   \n",
       " 12        Donna Fuscaldo  05112017  Investopedia  05042017   \n",
       " 13     Michael J. Kramer  05112017  Investopedia  05042017   \n",
       " 14        Donna Fuscaldo  05112017  Investopedia  05042017   \n",
       " 15        Donna Fuscaldo  05112017  Investopedia  05042017   \n",
       " 16        Daniel Liberto  05112017  Investopedia  05042017   \n",
       " 17         Rakesh Sharma  05112017  Investopedia  05042017   \n",
       " 18         Rakesh Sharma  05112017  Investopedia  05042017   \n",
       " 19        Daniel Liberto  05112017  Investopedia  05042017   \n",
       " 20        Donna Fuscaldo  05112017  Investopedia  05042017   \n",
       " 21         Todd Haselton  05112017          CNBC  05042017   \n",
       " 22         Todd Haselton  05112017          CNBC  05042017   \n",
       " 23                        05112017          CNBC  05042017   \n",
       " 24         Arjun Kharpal  05112017          CNBC  05042017   \n",
       " 25         Arjun Kharpal  05112017          CNBC  05042017   \n",
       " 26         Chantel McGee  05112017          CNBC  05042017   \n",
       " 27         Arjun Kharpal  05112017          CNBC  05042017   \n",
       " 28      Elizabeth Gurdus  05112017          CNBC  05042017   \n",
       " 29         Todd Haselton  05112017          CNBC  05042017   \n",
       " 30         Todd Haselton  05112017          CNBC  05042017   \n",
       " 31         Dan Caplinger  05112017          Fool  05042017   \n",
       " 32     Motley Fool Staff  05112017          Fool  05042017   \n",
       " 33         Jeremy Bowman  05112017          Fool  05042017   \n",
       " 34        Maurie Backman  05112017          Fool  05042017   \n",
       " 35            Danny Vena  05112017          Fool  05042017   \n",
       " 36       Steve Symington  05112017          Fool  05042017   \n",
       " 37    Bradley Seth McNew  05112017          Fool  05042017   \n",
       " 38          Maxx Chatsko  05112017          Fool  05042017   \n",
       " 39  Matthew Frankel, CFP  05112017          Fool  05042017   \n",
       " 40        Keith Speights  05112017          Fool  05042017   \n",
       " 41     Giovanni Legorano  05112017   MarketWatch  05042017   \n",
       " 42        Shawn Langlois  05112017   MarketWatch  05042017   \n",
       " 43           Jacob Passy  05112017   MarketWatch  05042017   \n",
       " 44                        05112017   MarketWatch  05042017   \n",
       " 45       Suzanne Vranica  05112017   MarketWatch  05042017   \n",
       " 46          Brett Arends  05112017   MarketWatch  05042017   \n",
       " 47                        05112017   MarketWatch  05042017   \n",
       " 48          Tomi Kilgore  05112017   MarketWatch  05042017   \n",
       " 49             Sue Chang  05112017   MarketWatch  05042017   \n",
       " 50          Sally French  05112017   MarketWatch  05042017   \n",
       " 51          Tomi Kilgore  05112017   MarketWatch  05042017   \n",
       " 52          Cullen Roche  05112017   MarketWatch  05042017   \n",
       " \n",
       "                                                  Text  \\\n",
       " 0   MILAN (Reuters) - Alphabet Inc’s  Google has a...   \n",
       " 1   (Reuters) - Microsoft Corp on Wednesday turned...   \n",
       " 2   The European Court of Justice will now have to...   \n",
       " 3   (Adds judge’s comment, ruling) BERLIN, May 9 (...   \n",
       " 4   The European Commission said on Wednesday in a...   \n",
       " 5   (Reuters) - Amazon.com Inc is dominating the n...   \n",
       " 6   LOS ANGELES (Reuters) - Family members of thre...   \n",
       " 7   LAGOS (Reuters) - Nigeria’s government should ...   \n",
       " 8   VIENNA (Reuters) - Facebook must remove postin...   \n",
       " 9   But a new tactic by Amazon to block these prog...   \n",
       " 10  WASHINGTON (Reuters) - U.S. Securities and Exc...   \n",
       " 11  Find the best broker for your trading or inves...   \n",
       " 12  Find the best broker for your trading or inves...   \n",
       " 13  Find the best broker for your trading or inves...   \n",
       " 14  Find the best broker for your trading or inves...   \n",
       " 15  Find the best broker for your trading or inves...   \n",
       " 16  Find the best broker for your trading or inves...   \n",
       " 17  Find the best broker for your trading or inves...   \n",
       " 18  Find the best broker for your trading or inves...   \n",
       " 19  Find the best broker for your trading or inves...   \n",
       " 20  Find the best broker for your trading or inves...   \n",
       " 21  Don't worry if you accidentally opened that Go...   \n",
       " 22  Images of Google's new operating system — whic...   \n",
       " 23  Family members of three victims of the Decembe...   \n",
       " 24  A top Apple executive revealed he is not a fan...   \n",
       " 25  Internet companies like Google and Apple are a...   \n",
       " 26  If there was any doubt that Silicon Valley hat...   \n",
       " 27  Google doesn't need to compete on price to bea...   \n",
       " 28  When Warren Buffett told Berkshire Hathaway sh...   \n",
       " 29  With just one single long press, you can save ...   \n",
       " 30  Picture it: you're standing in the kitchen coo...   \n",
       " 31  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 32  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 33  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 34  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 35  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 36  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 37  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 38  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 39  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 40  Founded in 1993 by brothers Tom and David Gard...   \n",
       " 41  Published: May 4, 2017 2:30 p.m. ET By ROME --...   \n",
       " 42  Published: May 4, 2017 4:05 p.m. ET ‘It’s more...   \n",
       " 43  Published: May 6, 2017 8:49 a.m. ET Skills tru...   \n",
       " 44  Username Password Remember me Forgot your pass...   \n",
       " 45  Published: May 9, 2017 7:22 a.m. ET By Possibl...   \n",
       " 46  Published: May 5, 2017 4:43 p.m. ET The wily r...   \n",
       " 47         Reference #18.a3a50517.1542076593.2f2da48    \n",
       " 48  Published: May 10, 2017 9:54 a.m. ET Apple rea...   \n",
       " 49  Published: May 10, 2017 5:48 p.m. ET Defensive...   \n",
       " 50  Published: May 10, 2017 6:29 p.m. ET It’s more...   \n",
       " 51  Published: May 9, 2017 7:33 a.m. ET Apple’s ma...   \n",
       " 52  Published: May 9, 2017 12:53 p.m. ET Why? They...   \n",
       " \n",
       "                                                 Title  \n",
       " 0   \n",
       "                 Google to pay $334 million to...  \n",
       " 1   \n",
       "                 Microsoft adds tools to flag ...  \n",
       " 2   \n",
       "                 German court refers publisher...  \n",
       " 3   \n",
       "                 UPDATE 1-German court refers ...  \n",
       " 4   \n",
       "                 EU to tackle complaints over ...  \n",
       " 5   \n",
       "                 Amazon sweeps U.S. market for...  \n",
       " 6   \n",
       "                 Families of San Bernardino sh...  \n",
       " 7   \n",
       "                 Nigeria should simplify taxes...  \n",
       " 8   \n",
       "                 Austrian court rules Facebook...  \n",
       " 9   \n",
       "                 Amazon trounces rivals in bat...  \n",
       " 10  \n",
       "                 U.S. SEC taps IPO lawyer for ...  \n",
       " 11  Google: No to Price War Over Cloud Computing |...  \n",
       " 12  YouTube to Spend Millions on Producing 40 New ...  \n",
       " 13       Google Is Eating Yelp's Lunch | Investopedia  \n",
       " 14  Microsoft Shutting Google Chrome Out Of Latest...  \n",
       " 15  Twitter Is Now Using AI to Recommend Tweets (T...  \n",
       " 16  Nasdaq 100 Will Continue to Outperform S&P 500...  \n",
       " 17  Tech's Trillion-Dollar Troika (AAPL, GOOG) | I...  \n",
       " 18  HBO to Remove Shows From Amazon Streaming by E...  \n",
       " 19  Alibaba's Alipay Takes on Apple and PayPal Wit...  \n",
       " 20  Microsoft, Facebook Create an Ad Tracker for E...  \n",
       " 21  What to do if you opened the Google Doc phishi...  \n",
       " 22  Google Fuchsia operating system images appear ...  \n",
       " 23  Facebook, Google, Twitter sued by families of ...  \n",
       " 24  Apple executive says he is not a fan of Amazon...  \n",
       " 25  Spotify CEO claims internet firms like Apple a...  \n",
       " 26  Google's Eric Schmidt: H-1B limit is stupidest...  \n",
       " 27  Google touts AI in the cloud to beat Amazon, M...  \n",
       " 28  Cramer's takeaways from Warren Buffett's Googl...  \n",
       " 29  How to download sites to read later in Chrome ...  \n",
       " 30              How to make calls with Amazon's Alexa  \n",
       " 31  \n",
       "       \n",
       "     Alphabet Stock Split: Will the Goo...  \n",
       " 32  \n",
       "       \n",
       "     Check Out The Motley Fool's Skill ...  \n",
       " 33  \n",
       "       \n",
       "     Instacart is Making AmazonFresh Lo...  \n",
       " 34  \n",
       "       \n",
       "     3 Reasons to Pay Off Your Mortgage...  \n",
       " 35  \n",
       "       \n",
       "     Is eBay Shopping for Shopify? -- T...  \n",
       " 36  \n",
       "       \n",
       "     Why Wayfair Inc. Stock Popped Toda...  \n",
       " 37  \n",
       "       \n",
       "     Why Mindbody Inc. Stock Dropped To...  \n",
       " 38  \n",
       "       \n",
       "     Here's Why Sunoco LP Rose 25.8% in...  \n",
       " 39  \n",
       "       \n",
       "     The 3 Best S&P 500 Index Funds -- ...  \n",
       " 40  \n",
       "       \n",
       "     10 Things Trumpcare Changes in Hea...  \n",
       " 41  Google reaches tax settlement in Italy - Marke...  \n",
       " 42  Alphabet’s Eric Schmidt says he’s a ‘denier’ w...  \n",
       " 43  Silicon Valley hires most graduates from this ...  \n",
       " 44  WPP's POSSIBLE Acquires Amazon Ecommerce Speci...  \n",
       " 45  WPP buys consulting firm specializing in Amazo...  \n",
       " 46  What companies could learn from the British mo...  \n",
       " 47                                      Access Denied  \n",
       " 48  Apple is first to cross $800 billion barrier -...  \n",
       " 49  Here’s the ‘closest thing to a sure bet’ in st...  \n",
       " 50  This is the most Instagrammed place in the wor...  \n",
       " 51  Apple’s stock surged to another record after B...  \n",
       " 52  Don’t ever listen to investing experts’ short-...  ]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stockPredict]",
   "language": "python",
   "name": "conda-env-stockPredict-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
