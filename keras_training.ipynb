{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 25 03:01:13 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-SXM2...  Off  | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    61W / 300W |  15815MiB / 16276MiB |     17%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-SXM2...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    41W / 300W |   5881MiB / 16276MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-SXM2...  Off  | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    50W / 300W |  15597MiB / 16276MiB |      2%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-SXM2...  Off  | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    72W / 300W |  15631MiB / 16276MiB |     55%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-SXM2...  Off  | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    59W / 300W |  15477MiB / 16276MiB |     26%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    44W / 300W |   1613MiB / 16276MiB |     21%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    80W / 300W |  15631MiB / 16276MiB |     79%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    49W / 300W |   9756MiB / 16276MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=5\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText = pd.read_csv('./mined/Combined/GoogleProcessed.csv')\n",
    "dfScore = pd.read_csv('./processedSelected/googl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['EndDate'] = pd.to_datetime(dfText['EndDate'], format='%m%d%Y')\n",
    "dfText['StartDate'] = pd.to_datetime(dfText['StartDate'], format='%m%d%Y')\n",
    "dfScore['Date'] = pd.to_datetime(dfScore['Date'])\n",
    "dfFinal = pd.merge(dfText, dfScore[['Date','FractionalIncrease','Positive']],how='left', left_on ='EndDate', right_on='Date').drop('Date',axis=1)\n",
    "dfFinal = dfFinal.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfFinal['Text'].values\n",
    "x = [x_.replace('\\r\\n','').replace('\\xa0','')for x_ in x]\n",
    "y = dfFinal['FractionalIncrease'].values\n",
    "yBinary = dfFinal['Positive'].values\n",
    "yBinary = [int(ybin)for ybin in yBinary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (np.asarray(X_train).reshape(-1,1), \n",
    "                                    np.asarray(X_test).reshape(-1,1), \n",
    "                                    np.asarray(y_train).reshape(-1,1), \n",
    "                                    np.asarray(y_test).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Initialize variable module/aggregation/scaling:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with aggregation/scaling\n",
      "INFO:tensorflow:Initialize variable module/aggregation/weights:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with aggregation/weights\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/W_cnn_0:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/W_cnn_0\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/W_cnn_1:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/W_cnn_1\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/W_cnn_2:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/W_cnn_2\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/W_cnn_3:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/W_cnn_3\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/W_cnn_4:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/W_cnn_4\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/W_cnn_5:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/W_cnn_5\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/W_cnn_6:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/W_cnn_6\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/b_cnn_0:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/b_cnn_0\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/b_cnn_1:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/b_cnn_1\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/b_cnn_2:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/b_cnn_2\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/b_cnn_3:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/b_cnn_3\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/b_cnn_4:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/b_cnn_4\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/b_cnn_5:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/b_cnn_5\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN/b_cnn_6:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN/b_cnn_6\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_0/W_carry:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_0/W_carry\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_0/W_transform:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_0/W_transform\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_0/b_carry:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_0/b_carry\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_0/b_transform:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_0/b_transform\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_1/W_carry:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_1/W_carry\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_1/W_transform:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_1/W_transform\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_1/b_carry:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_1/b_carry\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_high_1/b_transform:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_high_1/b_transform\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_proj/W_proj:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_proj/W_proj\n",
      "INFO:tensorflow:Initialize variable module/bilm/CNN_proj/b_proj:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/CNN_proj/b_proj\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable module/bilm/char_embed:0 from checkpoint /tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables with bilm/char_embed\n"
     ]
    }
   ],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)\n",
    "def ELMoEmbedding(x):\n",
    "    squeezed = tf.squeeze(tf.cast(x, tf.string))\n",
    "    return embed(squeezed, signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "# pred = Dense(2, activation='softmax')(dense)\n",
    "pred = Dense(1, activation='linear')(dense)\n",
    "model = Model(inputs=input_text, outputs=pred)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 104/1085 [=>............................] - ETA: 9:51 - loss: 0.1048 - mean_squared_error: 0.1048"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(X_train, y_train, epochs=1, batch_size=8)\n",
    "    model.save_weights('./elmo-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)\n",
    "\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "\n",
    "y = list(data['v1'])\n",
    "x = list(data['v2'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "test = encode(le, ['ham', 'spam', 'ham', 'ham'])\n",
    "\n",
    "untest = decode(le, test)\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)\n",
    "\n",
    "x_train = np.asarray(x_enc[:5000])\n",
    "y_train = np.asarray(y_enc[:5000])\n",
    "\n",
    "x_test = np.asarray(x_enc[5000:])\n",
    "y_test = np.asarray(y_enc[5000:])\n",
    "\n",
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "pred = Dense(2, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(x_train, y_train, epochs=1, batch_size=32)\n",
    "    model.save_weights('./elmo-model.h5')\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model.load_weights('./elmo-model.h5')  \n",
    "    predicts = model.predict(x_test, batch_size=32)\n",
    "\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Delta</th>\n",
       "      <th>FractionalIncrease</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>782.50</td>\n",
       "      <td>-27.50</td>\n",
       "      <td>-0.033951</td>\n",
       "      <td>810.060</td>\n",
       "      <td>743.590</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-25</td>\n",
       "      <td>782.61</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>793.770</td>\n",
       "      <td>772.650</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>778.55</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>799.740</td>\n",
       "      <td>773.145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>792.95</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.018496</td>\n",
       "      <td>792.000</td>\n",
       "      <td>753.360</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>817.36</td>\n",
       "      <td>24.41</td>\n",
       "      <td>0.030784</td>\n",
       "      <td>824.300</td>\n",
       "      <td>787.905</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>809.10</td>\n",
       "      <td>-8.26</td>\n",
       "      <td>-0.010106</td>\n",
       "      <td>823.000</td>\n",
       "      <td>804.500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>802.33</td>\n",
       "      <td>-6.77</td>\n",
       "      <td>-0.008367</td>\n",
       "      <td>816.000</td>\n",
       "      <td>802.440</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>807.50</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>813.430</td>\n",
       "      <td>789.620</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>828.38</td>\n",
       "      <td>20.88</td>\n",
       "      <td>0.025858</td>\n",
       "      <td>830.430</td>\n",
       "      <td>805.920</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>829.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>834.650</td>\n",
       "      <td>821.010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>859.05</td>\n",
       "      <td>30.05</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>858.794</td>\n",
       "      <td>823.960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>815.00</td>\n",
       "      <td>-44.05</td>\n",
       "      <td>-0.051278</td>\n",
       "      <td>867.000</td>\n",
       "      <td>812.250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>831.73</td>\n",
       "      <td>16.73</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>834.250</td>\n",
       "      <td>812.051</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-02-16</td>\n",
       "      <td>838.50</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>842.000</td>\n",
       "      <td>826.500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>851.08</td>\n",
       "      <td>12.58</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>853.790</td>\n",
       "      <td>837.260</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>856.31</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>858.000</td>\n",
       "      <td>841.442</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>853.69</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>856.930</td>\n",
       "      <td>841.170</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>870.53</td>\n",
       "      <td>16.84</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>869.880</td>\n",
       "      <td>852.670</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>841.39</td>\n",
       "      <td>-29.14</td>\n",
       "      <td>-0.033474</td>\n",
       "      <td>874.420</td>\n",
       "      <td>847.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>851.98</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.012586</td>\n",
       "      <td>851.585</td>\n",
       "      <td>824.300</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>849.50</td>\n",
       "      <td>-2.48</td>\n",
       "      <td>-0.002911</td>\n",
       "      <td>860.590</td>\n",
       "      <td>845.245</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>841.04</td>\n",
       "      <td>-8.46</td>\n",
       "      <td>-0.009959</td>\n",
       "      <td>853.590</td>\n",
       "      <td>834.600</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>859.74</td>\n",
       "      <td>18.70</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>860.200</td>\n",
       "      <td>837.850</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>890.00</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>892.990</td>\n",
       "      <td>857.500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>950.29</td>\n",
       "      <td>60.29</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>950.200</td>\n",
       "      <td>887.180</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>951.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>962.200</td>\n",
       "      <td>947.370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>943.20</td>\n",
       "      <td>-8.09</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>965.896</td>\n",
       "      <td>940.060</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>979.00</td>\n",
       "      <td>35.80</td>\n",
       "      <td>0.037956</td>\n",
       "      <td>978.115</td>\n",
       "      <td>941.270</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>990.96</td>\n",
       "      <td>11.96</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>999.600</td>\n",
       "      <td>977.820</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>1004.23</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>1008.610</td>\n",
       "      <td>981.290</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>948.02</td>\n",
       "      <td>-56.21</td>\n",
       "      <td>-0.055973</td>\n",
       "      <td>1005.600</td>\n",
       "      <td>936.795</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>976.87</td>\n",
       "      <td>28.85</td>\n",
       "      <td>0.030432</td>\n",
       "      <td>980.790</td>\n",
       "      <td>940.370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>951.35</td>\n",
       "      <td>-25.52</td>\n",
       "      <td>-0.026124</td>\n",
       "      <td>993.990</td>\n",
       "      <td>936.160</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>925.00</td>\n",
       "      <td>-26.35</td>\n",
       "      <td>-0.027697</td>\n",
       "      <td>951.660</td>\n",
       "      <td>915.310</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>970.80</td>\n",
       "      <td>45.80</td>\n",
       "      <td>0.049514</td>\n",
       "      <td>969.630</td>\n",
       "      <td>919.850</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>997.00</td>\n",
       "      <td>26.20</td>\n",
       "      <td>0.026988</td>\n",
       "      <td>995.600</td>\n",
       "      <td>964.800</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>969.18</td>\n",
       "      <td>-27.82</td>\n",
       "      <td>-0.027904</td>\n",
       "      <td>1006.190</td>\n",
       "      <td>960.230</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>949.10</td>\n",
       "      <td>-20.08</td>\n",
       "      <td>-0.020719</td>\n",
       "      <td>969.520</td>\n",
       "      <td>932.521</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>935.00</td>\n",
       "      <td>-14.10</td>\n",
       "      <td>-0.014856</td>\n",
       "      <td>952.490</td>\n",
       "      <td>933.920</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>942.95</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>949.900</td>\n",
       "      <td>921.220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>943.71</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>945.425</td>\n",
       "      <td>918.600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>946.30</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>946.310</td>\n",
       "      <td>919.310</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>944.25</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>958.330</td>\n",
       "      <td>932.680</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2017-09-14</td>\n",
       "      <td>946.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>952.850</td>\n",
       "      <td>937.500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>948.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>950.000</td>\n",
       "      <td>925.400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>956.25</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>965.430</td>\n",
       "      <td>924.510</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>972.79</td>\n",
       "      <td>16.54</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>977.740</td>\n",
       "      <td>955.550</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>1003.84</td>\n",
       "      <td>31.05</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>1007.570</td>\n",
       "      <td>970.270</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>1004.75</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>1016.310</td>\n",
       "      <td>1001.100</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>998.47</td>\n",
       "      <td>-6.28</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>1008.650</td>\n",
       "      <td>977.080</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>1039.99</td>\n",
       "      <td>41.52</td>\n",
       "      <td>0.041584</td>\n",
       "      <td>1063.620</td>\n",
       "      <td>990.470</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>1048.00</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>1062.690</td>\n",
       "      <td>1028.660</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     Open  Delta  FractionalIncrease      High       Low  \\\n",
       "0   2016-11-17   782.50 -27.50           -0.033951   810.060   743.590   \n",
       "1   2016-11-25   782.61   0.11            0.000141   793.770   772.650   \n",
       "2   2016-12-01   778.55  -4.06           -0.005188   799.740   773.145   \n",
       "3   2016-12-08   792.95  14.40            0.018496   792.000   753.360   \n",
       "4   2016-12-15   817.36  24.41            0.030784   824.300   787.905   \n",
       "5   2016-12-22   809.10  -8.26           -0.010106   823.000   804.500   \n",
       "6   2016-12-29   802.33  -6.77           -0.008367   816.000   802.440   \n",
       "7   2017-01-05   807.50   5.17            0.006444   813.430   789.620   \n",
       "8   2017-01-12   828.38  20.88            0.025858   830.430   805.920   \n",
       "9   2017-01-19   829.00   0.62            0.000748   834.650   821.010   \n",
       "10  2017-01-26   859.05  30.05            0.036248   858.794   823.960   \n",
       "11  2017-02-02   815.00 -44.05           -0.051278   867.000   812.250   \n",
       "12  2017-02-09   831.73  16.73            0.020528   834.250   812.051   \n",
       "13  2017-02-16   838.50   6.77            0.008140   842.000   826.500   \n",
       "14  2017-02-23   851.08  12.58            0.015003   853.790   837.260   \n",
       "15  2017-03-02   856.31   5.23            0.006145   858.000   841.442   \n",
       "16  2017-03-09   853.69  -2.62           -0.003060   856.930   841.170   \n",
       "17  2017-03-16   870.53  16.84            0.019726   869.880   852.670   \n",
       "18  2017-03-23   841.39 -29.14           -0.033474   874.420   847.000   \n",
       "19  2017-03-30   851.98  10.59            0.012586   851.585   824.300   \n",
       "20  2017-04-06   849.50  -2.48           -0.002911   860.590   845.245   \n",
       "21  2017-04-13   841.04  -8.46           -0.009959   853.590   834.600   \n",
       "22  2017-04-20   859.74  18.70            0.022234   860.200   837.850   \n",
       "23  2017-04-27   890.00  30.26            0.035197   892.990   857.500   \n",
       "24  2017-05-04   950.29  60.29            0.067742   950.200   887.180   \n",
       "25  2017-05-11   951.29   1.00            0.001052   962.200   947.370   \n",
       "26  2017-05-18   943.20  -8.09           -0.008504   965.896   940.060   \n",
       "27  2017-05-25   979.00  35.80            0.037956   978.115   941.270   \n",
       "28  2017-06-01   990.96  11.96            0.012217   999.600   977.820   \n",
       "29  2017-06-08  1004.23  13.27            0.013391  1008.610   981.290   \n",
       "30  2017-06-15   948.02 -56.21           -0.055973  1005.600   936.795   \n",
       "31  2017-06-22   976.87  28.85            0.030432   980.790   940.370   \n",
       "32  2017-06-29   951.35 -25.52           -0.026124   993.990   936.160   \n",
       "33  2017-07-06   925.00 -26.35           -0.027697   951.660   915.310   \n",
       "34  2017-07-13   970.80  45.80            0.049514   969.630   919.850   \n",
       "35  2017-07-20   997.00  26.20            0.026988   995.600   964.800   \n",
       "36  2017-07-27   969.18 -27.82           -0.027904  1006.190   960.230   \n",
       "37  2017-08-03   949.10 -20.08           -0.020719   969.520   932.521   \n",
       "38  2017-08-10   935.00 -14.10           -0.014856   952.490   933.920   \n",
       "39  2017-08-17   942.95   7.95            0.008503   949.900   921.220   \n",
       "40  2017-08-24   943.71   0.76            0.000806   945.425   918.600   \n",
       "41  2017-08-31   946.30   2.59            0.002744   946.310   919.310   \n",
       "42  2017-09-07   944.25  -2.05           -0.002166   958.330   932.680   \n",
       "43  2017-09-14   946.00   1.75            0.001853   952.850   937.500   \n",
       "44  2017-09-21   948.13   2.13            0.002252   950.000   925.400   \n",
       "45  2017-09-28   956.25   8.12            0.008564   965.430   924.510   \n",
       "46  2017-10-05   972.79  16.54            0.017297   977.740   955.550   \n",
       "47  2017-10-12  1003.84  31.05            0.031919  1007.570   970.270   \n",
       "48  2017-10-19  1004.75   0.91            0.000907  1016.310  1001.100   \n",
       "49  2017-10-26   998.47  -6.28           -0.006250  1008.650   977.080   \n",
       "50  2017-11-02  1039.99  41.52            0.041584  1063.620   990.470   \n",
       "51  2017-11-09  1048.00   8.01            0.007702  1062.690  1028.660   \n",
       "\n",
       "    Positive  \n",
       "0      False  \n",
       "1       True  \n",
       "2      False  \n",
       "3       True  \n",
       "4       True  \n",
       "5      False  \n",
       "6      False  \n",
       "7       True  \n",
       "8       True  \n",
       "9       True  \n",
       "10      True  \n",
       "11     False  \n",
       "12      True  \n",
       "13      True  \n",
       "14      True  \n",
       "15      True  \n",
       "16     False  \n",
       "17      True  \n",
       "18     False  \n",
       "19      True  \n",
       "20     False  \n",
       "21     False  \n",
       "22      True  \n",
       "23      True  \n",
       "24      True  \n",
       "25      True  \n",
       "26     False  \n",
       "27      True  \n",
       "28      True  \n",
       "29      True  \n",
       "30     False  \n",
       "31      True  \n",
       "32     False  \n",
       "33     False  \n",
       "34      True  \n",
       "35      True  \n",
       "36     False  \n",
       "37     False  \n",
       "38     False  \n",
       "39      True  \n",
       "40      True  \n",
       "41      True  \n",
       "42     False  \n",
       "43      True  \n",
       "44      True  \n",
       "45      True  \n",
       "46      True  \n",
       "47      True  \n",
       "48      True  \n",
       "49     False  \n",
       "50      True  \n",
       "51      True  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfScore['FractionalIncrease'].value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
