{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google = pd.read_csv('../data/mined/GOOGLE1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "embeddings = elmo(\n",
    "[\"the cat is on the mat\", \"dogs are in the fog\"],\n",
    "signature=\"default\",\n",
    "as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "tokens_input = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "[\"dogs\", \"are\", \"in\", \"the\", \"fog\", \"\"]]\n",
    "tokens_length = [6, 5]\n",
    "embeddings = elmo(\n",
    "inputs={\n",
    "\"tokens\": tokens_input,\n",
    "\"sequence_len\": tokens_length\n",
    "},\n",
    "signature=\"tokens\",\n",
    "as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sess.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 1024)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText = pd.read_csv('./mined/Combined/GoogleProcessed.csv')\n",
    "dfScore = pd.read_csv('./processedSelected/googl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['EndDate'] = pd.to_datetime(dfText['EndDate'], format='%m%d%Y')\n",
    "dfText['StartDate'] = pd.to_datetime(dfText['StartDate'], format='%m%d%Y')\n",
    "dfScore['Date'] = pd.to_datetime(dfScore['Date'])\n",
    "dfFinal = pd.merge(dfText, dfScore[['Date','FractionalIncrease','Positive']],how='left', left_on ='EndDate', right_on='Date').drop('Date',axis=1)\n",
    "dfFinal = dfFinal.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfFinal['Text'].values\n",
    "x = [x_.replace('\\r\\n','').replace('\\xa0','')for x_ in x]\n",
    "y = dfFinal['FractionalIncrease'].values\n",
    "yBinary = dfFinal['Positive'].values\n",
    "yBinary = [int(y)for y in yTrainBinary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (np.asarray(X_train).reshape(-1,1), \n",
    "                                    np.asarray(X_test).reshape(-1,1), \n",
    "                                    np.asarray(y_train).reshape(-1,1), \n",
    "                                    np.asarray(y_test).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)\n",
    "def ELMoEmbedding(x):\n",
    "    squeezed = tf.squeeze(tf.cast(x, tf.string))\n",
    "    return embed(squeezed, signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-221-07d1695deaf0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-221-07d1695deaf0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    input_text = Input(shape=(,1), dtype=tf.string)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "# pred = Dense(2, activation='softmax')(dense)\n",
    "pred = Dense(1, activation='linear')(dense)\n",
    "model = Model(inputs=input_text, outputs=pred)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  66/1085 [>.............................] - ETA: 36:02 - loss: 0.4250 - mean_squared_error: 0.4250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-081676f4937e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./elmo-model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cds/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/cds/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cds/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cds/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cds/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(X_train, y_train, epochs=1, batch_size=2)\n",
    "    model.save_weights('./elmo-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)\n",
    "\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "\n",
    "y = list(data['v1'])\n",
    "x = list(data['v2'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "test = encode(le, ['ham', 'spam', 'ham', 'ham'])\n",
    "\n",
    "untest = decode(le, test)\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)\n",
    "\n",
    "x_train = np.asarray(x_enc[:5000])\n",
    "y_train = np.asarray(y_enc[:5000])\n",
    "\n",
    "x_test = np.asarray(x_enc[5000:])\n",
    "y_test = np.asarray(y_enc[5000:])\n",
    "\n",
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "pred = Dense(2, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(x_train, y_train, epochs=1, batch_size=32)\n",
    "    model.save_weights('./elmo-model.h5')\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model.load_weights('./elmo-model.h5')  \n",
    "    predicts = model.predict(x_test, batch_size=32)\n",
    "\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Delta</th>\n",
       "      <th>FractionalIncrease</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>782.50</td>\n",
       "      <td>-27.50</td>\n",
       "      <td>-0.033951</td>\n",
       "      <td>810.060</td>\n",
       "      <td>743.590</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-25</td>\n",
       "      <td>782.61</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>793.770</td>\n",
       "      <td>772.650</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>778.55</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>799.740</td>\n",
       "      <td>773.145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>792.95</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.018496</td>\n",
       "      <td>792.000</td>\n",
       "      <td>753.360</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>817.36</td>\n",
       "      <td>24.41</td>\n",
       "      <td>0.030784</td>\n",
       "      <td>824.300</td>\n",
       "      <td>787.905</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>809.10</td>\n",
       "      <td>-8.26</td>\n",
       "      <td>-0.010106</td>\n",
       "      <td>823.000</td>\n",
       "      <td>804.500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>802.33</td>\n",
       "      <td>-6.77</td>\n",
       "      <td>-0.008367</td>\n",
       "      <td>816.000</td>\n",
       "      <td>802.440</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>807.50</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>813.430</td>\n",
       "      <td>789.620</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>828.38</td>\n",
       "      <td>20.88</td>\n",
       "      <td>0.025858</td>\n",
       "      <td>830.430</td>\n",
       "      <td>805.920</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>829.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>834.650</td>\n",
       "      <td>821.010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>859.05</td>\n",
       "      <td>30.05</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>858.794</td>\n",
       "      <td>823.960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>815.00</td>\n",
       "      <td>-44.05</td>\n",
       "      <td>-0.051278</td>\n",
       "      <td>867.000</td>\n",
       "      <td>812.250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>831.73</td>\n",
       "      <td>16.73</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>834.250</td>\n",
       "      <td>812.051</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-02-16</td>\n",
       "      <td>838.50</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>842.000</td>\n",
       "      <td>826.500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>851.08</td>\n",
       "      <td>12.58</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>853.790</td>\n",
       "      <td>837.260</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>856.31</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>858.000</td>\n",
       "      <td>841.442</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>853.69</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>856.930</td>\n",
       "      <td>841.170</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>870.53</td>\n",
       "      <td>16.84</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>869.880</td>\n",
       "      <td>852.670</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>841.39</td>\n",
       "      <td>-29.14</td>\n",
       "      <td>-0.033474</td>\n",
       "      <td>874.420</td>\n",
       "      <td>847.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>851.98</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.012586</td>\n",
       "      <td>851.585</td>\n",
       "      <td>824.300</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>849.50</td>\n",
       "      <td>-2.48</td>\n",
       "      <td>-0.002911</td>\n",
       "      <td>860.590</td>\n",
       "      <td>845.245</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>841.04</td>\n",
       "      <td>-8.46</td>\n",
       "      <td>-0.009959</td>\n",
       "      <td>853.590</td>\n",
       "      <td>834.600</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>859.74</td>\n",
       "      <td>18.70</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>860.200</td>\n",
       "      <td>837.850</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>890.00</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>892.990</td>\n",
       "      <td>857.500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>950.29</td>\n",
       "      <td>60.29</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>950.200</td>\n",
       "      <td>887.180</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>951.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>962.200</td>\n",
       "      <td>947.370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>943.20</td>\n",
       "      <td>-8.09</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>965.896</td>\n",
       "      <td>940.060</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>979.00</td>\n",
       "      <td>35.80</td>\n",
       "      <td>0.037956</td>\n",
       "      <td>978.115</td>\n",
       "      <td>941.270</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>990.96</td>\n",
       "      <td>11.96</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>999.600</td>\n",
       "      <td>977.820</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>1004.23</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>1008.610</td>\n",
       "      <td>981.290</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>948.02</td>\n",
       "      <td>-56.21</td>\n",
       "      <td>-0.055973</td>\n",
       "      <td>1005.600</td>\n",
       "      <td>936.795</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>976.87</td>\n",
       "      <td>28.85</td>\n",
       "      <td>0.030432</td>\n",
       "      <td>980.790</td>\n",
       "      <td>940.370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>951.35</td>\n",
       "      <td>-25.52</td>\n",
       "      <td>-0.026124</td>\n",
       "      <td>993.990</td>\n",
       "      <td>936.160</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>925.00</td>\n",
       "      <td>-26.35</td>\n",
       "      <td>-0.027697</td>\n",
       "      <td>951.660</td>\n",
       "      <td>915.310</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>970.80</td>\n",
       "      <td>45.80</td>\n",
       "      <td>0.049514</td>\n",
       "      <td>969.630</td>\n",
       "      <td>919.850</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>997.00</td>\n",
       "      <td>26.20</td>\n",
       "      <td>0.026988</td>\n",
       "      <td>995.600</td>\n",
       "      <td>964.800</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>969.18</td>\n",
       "      <td>-27.82</td>\n",
       "      <td>-0.027904</td>\n",
       "      <td>1006.190</td>\n",
       "      <td>960.230</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>949.10</td>\n",
       "      <td>-20.08</td>\n",
       "      <td>-0.020719</td>\n",
       "      <td>969.520</td>\n",
       "      <td>932.521</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>935.00</td>\n",
       "      <td>-14.10</td>\n",
       "      <td>-0.014856</td>\n",
       "      <td>952.490</td>\n",
       "      <td>933.920</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>942.95</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>949.900</td>\n",
       "      <td>921.220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>943.71</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>945.425</td>\n",
       "      <td>918.600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>946.30</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>946.310</td>\n",
       "      <td>919.310</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>944.25</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>958.330</td>\n",
       "      <td>932.680</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2017-09-14</td>\n",
       "      <td>946.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>952.850</td>\n",
       "      <td>937.500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>948.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>950.000</td>\n",
       "      <td>925.400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>956.25</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>965.430</td>\n",
       "      <td>924.510</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>972.79</td>\n",
       "      <td>16.54</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>977.740</td>\n",
       "      <td>955.550</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>1003.84</td>\n",
       "      <td>31.05</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>1007.570</td>\n",
       "      <td>970.270</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>1004.75</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>1016.310</td>\n",
       "      <td>1001.100</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>998.47</td>\n",
       "      <td>-6.28</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>1008.650</td>\n",
       "      <td>977.080</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>1039.99</td>\n",
       "      <td>41.52</td>\n",
       "      <td>0.041584</td>\n",
       "      <td>1063.620</td>\n",
       "      <td>990.470</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>1048.00</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>1062.690</td>\n",
       "      <td>1028.660</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     Open  Delta  FractionalIncrease      High       Low  \\\n",
       "0   2016-11-17   782.50 -27.50           -0.033951   810.060   743.590   \n",
       "1   2016-11-25   782.61   0.11            0.000141   793.770   772.650   \n",
       "2   2016-12-01   778.55  -4.06           -0.005188   799.740   773.145   \n",
       "3   2016-12-08   792.95  14.40            0.018496   792.000   753.360   \n",
       "4   2016-12-15   817.36  24.41            0.030784   824.300   787.905   \n",
       "5   2016-12-22   809.10  -8.26           -0.010106   823.000   804.500   \n",
       "6   2016-12-29   802.33  -6.77           -0.008367   816.000   802.440   \n",
       "7   2017-01-05   807.50   5.17            0.006444   813.430   789.620   \n",
       "8   2017-01-12   828.38  20.88            0.025858   830.430   805.920   \n",
       "9   2017-01-19   829.00   0.62            0.000748   834.650   821.010   \n",
       "10  2017-01-26   859.05  30.05            0.036248   858.794   823.960   \n",
       "11  2017-02-02   815.00 -44.05           -0.051278   867.000   812.250   \n",
       "12  2017-02-09   831.73  16.73            0.020528   834.250   812.051   \n",
       "13  2017-02-16   838.50   6.77            0.008140   842.000   826.500   \n",
       "14  2017-02-23   851.08  12.58            0.015003   853.790   837.260   \n",
       "15  2017-03-02   856.31   5.23            0.006145   858.000   841.442   \n",
       "16  2017-03-09   853.69  -2.62           -0.003060   856.930   841.170   \n",
       "17  2017-03-16   870.53  16.84            0.019726   869.880   852.670   \n",
       "18  2017-03-23   841.39 -29.14           -0.033474   874.420   847.000   \n",
       "19  2017-03-30   851.98  10.59            0.012586   851.585   824.300   \n",
       "20  2017-04-06   849.50  -2.48           -0.002911   860.590   845.245   \n",
       "21  2017-04-13   841.04  -8.46           -0.009959   853.590   834.600   \n",
       "22  2017-04-20   859.74  18.70            0.022234   860.200   837.850   \n",
       "23  2017-04-27   890.00  30.26            0.035197   892.990   857.500   \n",
       "24  2017-05-04   950.29  60.29            0.067742   950.200   887.180   \n",
       "25  2017-05-11   951.29   1.00            0.001052   962.200   947.370   \n",
       "26  2017-05-18   943.20  -8.09           -0.008504   965.896   940.060   \n",
       "27  2017-05-25   979.00  35.80            0.037956   978.115   941.270   \n",
       "28  2017-06-01   990.96  11.96            0.012217   999.600   977.820   \n",
       "29  2017-06-08  1004.23  13.27            0.013391  1008.610   981.290   \n",
       "30  2017-06-15   948.02 -56.21           -0.055973  1005.600   936.795   \n",
       "31  2017-06-22   976.87  28.85            0.030432   980.790   940.370   \n",
       "32  2017-06-29   951.35 -25.52           -0.026124   993.990   936.160   \n",
       "33  2017-07-06   925.00 -26.35           -0.027697   951.660   915.310   \n",
       "34  2017-07-13   970.80  45.80            0.049514   969.630   919.850   \n",
       "35  2017-07-20   997.00  26.20            0.026988   995.600   964.800   \n",
       "36  2017-07-27   969.18 -27.82           -0.027904  1006.190   960.230   \n",
       "37  2017-08-03   949.10 -20.08           -0.020719   969.520   932.521   \n",
       "38  2017-08-10   935.00 -14.10           -0.014856   952.490   933.920   \n",
       "39  2017-08-17   942.95   7.95            0.008503   949.900   921.220   \n",
       "40  2017-08-24   943.71   0.76            0.000806   945.425   918.600   \n",
       "41  2017-08-31   946.30   2.59            0.002744   946.310   919.310   \n",
       "42  2017-09-07   944.25  -2.05           -0.002166   958.330   932.680   \n",
       "43  2017-09-14   946.00   1.75            0.001853   952.850   937.500   \n",
       "44  2017-09-21   948.13   2.13            0.002252   950.000   925.400   \n",
       "45  2017-09-28   956.25   8.12            0.008564   965.430   924.510   \n",
       "46  2017-10-05   972.79  16.54            0.017297   977.740   955.550   \n",
       "47  2017-10-12  1003.84  31.05            0.031919  1007.570   970.270   \n",
       "48  2017-10-19  1004.75   0.91            0.000907  1016.310  1001.100   \n",
       "49  2017-10-26   998.47  -6.28           -0.006250  1008.650   977.080   \n",
       "50  2017-11-02  1039.99  41.52            0.041584  1063.620   990.470   \n",
       "51  2017-11-09  1048.00   8.01            0.007702  1062.690  1028.660   \n",
       "\n",
       "    Positive  \n",
       "0      False  \n",
       "1       True  \n",
       "2      False  \n",
       "3       True  \n",
       "4       True  \n",
       "5      False  \n",
       "6      False  \n",
       "7       True  \n",
       "8       True  \n",
       "9       True  \n",
       "10      True  \n",
       "11     False  \n",
       "12      True  \n",
       "13      True  \n",
       "14      True  \n",
       "15      True  \n",
       "16     False  \n",
       "17      True  \n",
       "18     False  \n",
       "19      True  \n",
       "20     False  \n",
       "21     False  \n",
       "22      True  \n",
       "23      True  \n",
       "24      True  \n",
       "25      True  \n",
       "26     False  \n",
       "27      True  \n",
       "28      True  \n",
       "29      True  \n",
       "30     False  \n",
       "31      True  \n",
       "32     False  \n",
       "33     False  \n",
       "34      True  \n",
       "35      True  \n",
       "36     False  \n",
       "37     False  \n",
       "38     False  \n",
       "39      True  \n",
       "40      True  \n",
       "41      True  \n",
       "42     False  \n",
       "43      True  \n",
       "44      True  \n",
       "45      True  \n",
       "46      True  \n",
       "47      True  \n",
       "48      True  \n",
       "49     False  \n",
       "50      True  \n",
       "51      True  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfScore['FractionalIncrease'].value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cds]",
   "language": "python",
   "name": "conda-env-cds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
